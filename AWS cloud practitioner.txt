https://www.udemy.com/course/practice-exams-aws-certified-cloud-practitioner/?couponCode=APR_24_GET_STARTED
    For exam practice
        (ALSO each chapter has questions html page at the end..)

==============================================================================================================
03 What is Cloud Computing?

    Examples of cloud computing types:
        - IaaS -> Amazon EC2, GCP, Digital Ocean
        - PaaS -> Elastic Bean Stack(AWS), Google App Engine
        - SaaS -> Rekognition for Machine learning on AWS, Dropbox, Zoom

    An AWS Region is a cluster of data centers
    A region has between 2 and 6 availability zones...each availability zone has redundant power, networking and
    connectivity..so they are isolated from disasters.

    AWS points of presence (edge locations) - these make content to be delivered to customers with lower latency

    Some services, like Route 53, IAM are Global...while other are regional (like EC2).
    NOT all AWS services are available in all the regions. You can see on their website if a specific service is available
    or not for a specific region.

!!!    Shared responsibility model
        This means that you as a developer are responsible for the security IN the cloud (customer data, app security,
        OS, firewall config, server side encryption etc) while AWS is responsible for the security OF the cloud...(the
        hardware, infrastructure, physical security)
            TODO Dan: question about this come in the exam


==============================================================================================================
04 IAM - Identity and Access Management

    We already used IAM when we created the root account. (also when I created accounts for the shopping app)

    Root account should not be used or shared...just to create other users

    Users can be grouped in a Group.
    Groups can only contain Users, not other Groups.
    A User can belong to multiple Groups

    Users and Groups can have json documents assigned which are called Policies

!!!!In AWS you apply the least privileged principle: don't give more permissions than the user needs.

    DanCurs     user created

    A Policy is a json document, that contains a version, and one or more Statements.
    The Statement element has several important parts:
        - effect : whether the Statement allows or denies access
        - principal : user/account/role for which the Statement applies
        - action : list of actions that are being allowed or denied
        - resource : list of resources to which the actions are applied

    Users on AWS console should use MFA (multi factor authentication)

    3 ways to connect to AWS:
        - AWS web console                       (protected by password and MFA)
        - AWS CLI (command line interface)      (PROTECTED by keys)
        - AWS SDK                               (PROTECTED by keys)

    Acess keys are generated from the AWS console.

    Installed AWS CLI on the machine :)
        "The AWS CLI first checks environment variables for credentials. If you've set the AWS_ACCESS_KEY_ID and
        AWS_SECRET_ACCESS_KEY environment variables, those will be used for authentication. You can check your
        system's environment variables to see if they're set."
            Dan: because i used this setup, when i worked in the past on the shop app, for uploading S3 pictures,
            now when i follow the tutorial, i created an AWS CLI profile, called "dancurs"..which needs to be specified
            each time i run an AWS CLI command, otherwise it will use the env variable key, which only has S3 permissions

    Example:
        aws iam list-users --profile dancurs

    An alternative to AWS CLI is AWS cloud shell.
        "AWS CloudShell is a browser-based shell that gives you command-line access to your AWS resources in the
        selected AWS region. AWS CloudShell comes pre-installed with popular tools for resource management and creation.
        You have the same credentials as you used to log in to the console"

        So since you are logged in the web console, no need to hassle with generating keys etc
    Example:
         aws iam list-users

    AWS Cloud shell offers space as well...so if you create files there etc...they will be "persisted"
        "Storage included 1 GB of storage free per AWS region"

    Some AWS services will need to perform actions on your behalf. To do so, we will assign permissions to AWS Services,
    with IAM Roles.
        Example if you start an EC2 instance (virtual server) and you want this to access some AWS service, like listing users,
        then you need to assign a role to EC2. They are also often used with Lambda.

    Auditing ..If you select a user and go to  the Access Advisor tab, you can see what AWS Services he accessed and when.
    This tool is very useful as if you notice that a user does not use some services, you can remove access for those services, and
    thus minimize the no of operations that he can perform.
    Similarly there is a Credentials Report, that lists all IAM users in your account, shows the status of access keys
    for each user, including:
    Access Key ID: The unique identifier for the access key. Status: Indicates whether the access key is active or inactive.
    Last Used Date: The date and time when the access key was last used for an API call (if applicable).


==============================================================================================================
05 EC2 - Elastic Compute Cloud

    This is Infrastructure as a service offering from Amazon
    It mainly consists of:
        - Renting Virtual Machines (EC2)
        - Storing data on virtual drives (EBS)
        - Distributing Load across Machines (ELB)

    Sizing and configuration options :
        - operating system : linux, windows, macos
        - CPU
        - RAM
        - storage :
            - network attached (EBS)
            - hardware (ECS instance store)
        - network card
        - firewall rules
        - bootstrap script, configure at first launch

    Bootstrap script allows you to                  (this script runs with root acess)
        - install updates
        - install software
        - download files from the internet
        - anything else you might think about

            Example used in the course:  (this will launch a webserver and write a html file to it)
#!/bin/bash
# Use this for your user data (script from top to bottom)
# install httpd (Linux 2 version)
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
echo "<h1>Hello World from $(hostname -f)</h1>" > /var/www/html/index.html

!!!!!
    In order to make the EC2 accessible via ssh and from the outside world, check out the youtube tutorial from the end
    (" AWS how to setup VPC, Public, Private Subnet, NAT, Internet Gateway, Route Table?")
    and the diagram "AWS VPC Subnet InternetGateway RouteTable.png" to better understand the networking elements.

    EC2 instance types
    https://aws.amazon.com/ec2/instance-types/
        General Purpose
            General purpose instances provide a balance of compute, memory and networking resources, and can be used
            for a variety of diverse workloads. These instances are ideal for applications that use these resources in
            equal proportions such as web servers and code repositories.
            Applications built on open-source software such as application servers, microservices, gaming servers,
            midsize data stores, and caching fleets.

        Compute Optimized
            Compute Optimized instances are ideal for compute bound applications that benefit from high performance
            processors. Instances belonging to this category are well suited for batch processing workloads, media
            transcoding, high performance web servers, high performance computing (HPC), scientific modeling, dedicated
            gaming servers and ad server engines, machine learning inference and other compute intensive applications.

        Memory Optimized
            Memory optimized instances are designed to deliver fast performance for workloads that process large data
            sets in memory.

        Accelerated Computing
            Accelerated computing instances use hardware accelerators, or co-processors, to perform functions, such as
            floating point number calculations, graphics processing, or data pattern matching, more efficiently than
            is possible in software running on CPUs.

        Storage Optimized
            Storage optimized instances are designed for workloads that require high, sequential read and write access
            to very large data sets on local storage. They are optimized to deliver tens of thousands of low-latency,
            random I/O operations per second (IOPS) to applications.
                Usecases:
                    SQL and NoSQL dbs
                    cache for in memory DB like Redis
                    data warehouse apps
                    distributed file systems

        HPC Optimized
            High performance computing (HPC) instances are purpose built to offer the best price performance for running
            HPC workloads at scale on AWS. HPC instances are ideal for applications that benefit from high-performance
            processors such as large, complex simulations and deep learning workloads.

    Security groups
        - are the fundamental of network security in AWS
        - they control how traffic is allowed into or out of our EC2 instances
        - security groups only contain allow rules !!!!!

        - they act as a firewall on our EC2 instances
        - one security group can be attached to multiple EC2 instances, and one EC2 instance can also have multiple
        security groups
        - all inbound traffic is BLOCKED by default
        - all outbound traffic is ALLOWED by default

        Dan: see "05- security groups diagram.png"

    Classic ports to know
        - 22 = SSH (secure shell) - log into linux instance
        - 21 = FTP - upload files
        - 22 = SFTP (secure file transfer protocol) - upload files using SSH
        - 80 = HTTP - access unsecure websites
        - 443 = HTTPS - access secure websites
        - 3389 = RDP (remote desktop protocol) - log into a Windows instance

        http://13.60.59.239/

    SSH to EC2 instance
        ssh -i EC2-Tutorial.pem ec2-user@ec2-13-60-59-239.eu-north-1.compute.amazonaws.com
            - you need to run this command from the secrets folder where the EC2-Tutorial.pem file contains a private key,
            that was either generated or selected during instance creation
            - ec2-user is  user created for linux that is running on the instance

        sudo -s (to become root)

!!! You should assign a role to the EC2 instance, by selecting the instance and going to Actions -> Security -> Modify IAM role.
    After doing the above step if you look into the EC2 instance settings ,in the Security tab you should see the IAM role.
    If you assign a role like "DemoRoleForEC2" that has "IAMReadOnlyAccess" permission, then in the ssh console you can
    run something like
        "aws iam list-users"

!!! Which purchasing option is better for me ?      (using a resort as an analogy for EC2)
        - On demand : coming and staying in a resort, whenever we like, we pay the full price.
        - Reserved : like planning ahead, and if we plan to stay for a long time (1-3 years), we may get a good discount
        - Savings plan : pay a certain amount per hour for certain period and stay in any room type(eg King Suite, Sea View)
        - Spot instances: the hotel allows people to bid for the empty rooms and the highest bidder keeps the rooms. You can
            get kicked out at any time. (so this is for jobs/processes that can handle being killed any time)
        - Dedicated hosts: we book an entire building of the resort
        - capacity reservations : you book a room for a period with full price, even if you do not stay in it

        Dan: see "5-2 price comparison.png"


==============================================================================================================
06 EC2 Instance Storage

    EBS Volume
     - means "elastic block store" is a network drive that you can attach to your instances while they run
     - allows you to persist instance data, even after their termination; this means that one can terminante an instance
     and after some time start a new instance, with the same EBS volume and have access to the same data that the previous
     EC2 instance had
     - an EBS can be mounted only for one EC2 instance at a time; however one EC2 instance can have multiple EBS volumes
     - they are bound to availability zones
     - think of them as a network USB stick !!!
     - the connection between EBS and EC2 is via a network which means that latency can occur
!!!  - when you create an EBS it has a flag "Delete on termination" ...which if set to true, when the EC2 is terminated,
        will be deleted
      - EBS snapshots are a backup of of your EBS volume at a moment in time
      - you can copy EBS snapshots across availability zones or regions
      - EBS snapshot archive is a storage that is 75% cheaper...but this means that it will take betweem 24 an 72 hours to
      retrieve that archive...so cheaper means slower :)
      - there is also a Recycle Bin feature for which you can set up rules as in how many days to keep there a delete snapshot,
      this is obviously useful in cases of accidental deletion

    AMI
        - amazon machine image
        - customization of an EC2 instance...you add your own software, configuration, operating system etc
        - this provides faster boot time because all your software is pre-packaged
        - are built for a specific region, and then they can be copied across regions
        - we can make and maintain our own AMI; you would create an EC2 instance, customize it how you want, then when
        ready, you stop it to maintain data integrity. Then you can build the AMI (this will also create EBS snapshots) and
        finally you can use that custom AMI
        - or you can buy AMIs from the marketplace

    EC2 image builder
        - used to automate the creation of Virtual machines or container images
        => automate the creation, maintain, validate and test EC2 AMIs
        - can be run on a schedule
        - the output of a builder can be an AMI or a Docker image
            Dan: mi-a dat eroare cand am urmat pasiii...aparent instanta de EC2 care ar fi trebuit sa ruleze procesul de
            creare al imaginii avea probleme...pe care nu am mai stat sa le identific..
        - cu DanPipe2 am reusit sa fac AMI... practic am lasat default la un pasul unde e "Create infrastructure
        configuration using service defaults" ...asta foloseste un EC2 instance care costa bani ...insa ideea e sa opresc
        EC2 dupa ce termina de creat imaginea

    EC2 Instance store
        - if you need high performance hard disk you must use EC2 instance store
        - better I/O performance
        - EC2 instance store lose their storage data if they are stopped...so this is suited for buffer / cache/ temporary
        data
        - for long term storage EBS is the choice

    EFS - Elastic file system
        - this is a managed NFS (network file system) that can be mounted on 100s of EC2 instances at a time, even if
        these EC2s are located in multiple availability zones
        - works with linux instances
        - a variant of this is EFS Infrequent Access (EFS-IA) , which is a storage class that is optimized for files not accessed
        every day (up to 92% lower costs)
        - EFS can be configured to automatically move files to EFS-IA after a certain period of time since they were last
        accessed

    Amazon FSx
        - use 3rd party high performance file systems on AWS (in case you do not like the offered storage options from
        AWS...or you want to store some data on your servers instead of Amazons for various reasons)
        -  Amazon FSx for windows file server
        -  Amazon FSx for Lustre (name is derived from "Linux" and "cluster")


==============================================================================================================
07 ELB & ASG - Elastic Load Balancing & Auto Scaling Groups

    - Vertical scalability means increasing the size of the instance...imagine a call center...and a Junior employee,
    vertical scaling would mean to replace him with a senior employee when there are too many calls
        so go from t3.micro to t3.large instance
    - there is a limit on how much you can scale this way : the hardware

    - Horizontal scalability ...means increasing the number of instances ...so in the call center example, this means
    adding more employees based on demand

    - High availability goes hand in hand with Horizontal scalability...and it means that your system runs in at least
    2 availability zones...in the call center example it means to have a call center in New York and another one in London

    - a load balancer is a server that forwards internet traffic to multiple servers (EC2 instances). By using one you can
    expose a single point of access (DNS) for your application
    - the load balancer will not direct traffic to a failling instance, because it performs regular health checks
    - you can use a load balancer across multiple availability zones

    - ELB (Elastic Load Balancer) is a managed load balancer...AWS guarantees that it will be working and takes care of
    upgrades, maintenance etc
    - AWS offers 3 kinds of ELBs:
        1. application load balancer (HTTP/HTTPS only)
        2. network load balancer (allows TCP...maybe for gaming, offer higher performance)
        3. classic load balancer (this offering is being retired by Amazon)

    Dan: see "AWS Load Balancer to 2 EC2 instances .png" to understand the elements needed to be configured for a load
        balancer...there is a youtube video about this below as well..

    - Auto Scaling groups are collections of Amazon EC2 instances that enable automatic scaling and fleet
    management features. These features help you maintain the health and availability of your applications.
    - you can choose various metrics, like CPU usage, and once the running EC2 instances reach that CPU usage threshold,
    new EC2 instances are created.
    - these new instances are added to the Target Group that is configured for the Load Balancer..


==============================================================================================================
08 S3

    - "infinitely scaling storage"
    - for example when you do an EBS snapshot, this is stored on S3

    Use cases
        - backup and storage
        - disaster recovery
        - archive
        - application and media storing
        - data lakes and big data analytics
        - software delivery
        - static website

    - allows users to store objects (files) into buckets (directories)
    - buckets must have a globally unique name, across all regions and accounts !!!!
    - buckets are defined at region level
    - naming convention for buckets
        - no uppercase
        - no underscore
        - 3-63 chars long
        - not ip
        - should start with lowecare or number

    - objects have a key.. an Amazon S3 object key acts like a unique identifier within a specific S3 bucket
        ex : for s3://my-bucket/my_file.txt the key is my_file.txt
                 s3://my-bucket/randomDirectory/my_file.txt the key is randomDirectory/my_file.txt
                 in this case the "randomDirectory" is called prefix

    - you can also add metadata (list of key-value pairs)
    - you can also add tag, (unicode key/value pair...up to 10..) useful for security and lifecycle
    - you can also have version id

    S3 Security
        - 1. IAM policies - which API calls should be allowed for a specific user from IAM console
        - 2. bucket policies - bucket wide rules from S3 console - allows cross account ...JSON based look similar to IAM policies
            - they specify the resources (buckets and objects and the set of API to allow or deny), the actions (set of
            API to allow or deny), the effect (allow or deny) and the principal (user or account to which the policy applies)
        - 3. Object Access Control List (ACL) - finer grain
        - 4. encryption - encrypt objects in S3 using encryption keys

    S3 Versioning
        - it is enabled at bucket level
        - same key overwrite will increment the version : 1, 2, 3 ...
        - it is a best practice to version your buckets:
            - protects against unwanted deletes
            - easy to roll back to previous version
        - suspending versioning does not delete old versions

    S3 Access logs
        - for audit purposes, you may want to log access to S3 buckets
        - any request, made to S3, FROM any account, authorized or unauthorized, will be logged into another S3 bucket
        - those logs can be analyzed with an analysis tool
        Dan: the logs will appear in the logs bucket after about an hour...so with delay...

    S3 Replication
        - 2 types, CRR (cross regional replication) and SRR (same region replication)
        - in order for this to work, you must enable versioning both in the source and the destination bucket
        - the copy process happens behind the scenes, and is asynchronous
        - we must give proper IAM permission to S3

    S3 Durability and Availability
        - durability : if you store 10 mil objects in S3, you can expect to lose 1 object once every 10.000 years; durability
        is the same for all storage classes (see below)
        - availability : how readily available a service is; this depends on the storage class...for example S3 standard has
        99.99% availability, which means not available 53 minutes per year

    S3 storage classes
        - S3 standard general purpose
            - 99.99% availability
        - S3 STANDARD infrequent access
            - lower cost than S3 standard..usecase would be backups / disaster recovery
            - 99.9% availability
        - S3 one zone infrequent access
            - high durability in one availability zone, but data is lost if availability zone is destroyed
            - uses cases would be secondary backups of on premise data, or data that you can recreate
        - S3 glacier instant retrieval
            - low cost object storage used for archive / backup             (applies to all glacier)
            - price is per storage + retrieval cost                          (applies to all glacier)
            - milliseccond retrieval
            - usecase...great for data that is accessed once per quarter for example
        - S3 glacier flexible retrieval
            - various longer retrieval times offered
        - S3 glacier deep archive
            - long storage.. lowest cost ....retrieval is in 12 hours +
        - S3 intelligent tiering
            - moves objects between tiers based on usage...for this extra functionality you pay a small fee, however
            there are no retrieval charges in S3 intelligent tiering

        Dan: when you upload a file you can specify the Storage Class..default one is Standard...also you can move objects
        to different classes depinding on needs

    S3 encryption
        - server side encryption means that the server, S3 in this case, encrypts the file after recieving it.
        - client side encryption means that the file is encrypted before uploading it

    AWS snow family
        - highly secure, portable devices, to collect and process data at the edge and migrate data into our out of AWS
        - this service is useful when dealing with a lot of data, since upload times over the internet can take too much
         time when dealing with TBs or PBs of data ...even exabytes EB (1 EB = 100O PB = 1_000_000 TB )

    AWS storage gateway
        - is a bridge between on premise data and cloud data in S3


==============================================================================================================
09 Databases & Analytics

    - If you want to structure data you will need a database
    - you can define relationships between datasets
    - various types of DBs
        - Relational Databases
        - NoSQL
            - NOT relational DBs
            - flexible schema..easier to evolve data model...data can be nested, support for arrays (think of a JSON document
            DB)
            - you can do horizontal scaling
            - examples : key-value DBs, document, graph, in memory

    - sure you can run a DB yourself on an EC2 instance, but in that case you need to manually handle things like resiliency,
    backups, patching, high availability, scaling, fault tolerance etc
    - in this chapter we go through all DBs offered by Amazon

    RDS ( Relational Database Service )
        - allows creation of DBs in the cloud that will be managed by AWS
        - various types of DBs: Postgres, MySql, Maria DB, Oracle, MS SQL server, Aurora (proprietary of AWS..not open sourced)
        - we have the possibility to add read replicas for our DB for improving the read performance
        - you can't SSH into your DB instance :(

        - Aurora is a cloud optimized DB and claims 5x performance improvement over MySQL running on RDS, and over 3x performance
        over Postgres running on RDS
            (Using Aurora locks you into the AWS ecosystem, making it harder to migrate to another cloud provider if needed.)
        - Aurora is not in the free tier...

    Amazon ElastiCache
        - ElastiCache is used to get a managed Redis or Memcached
        - caches are in memory DBs with high performance and low latency
        - this helps reduce load off databases for read intense workloads

    Dynamo DB
        - highly available DB with replication across 3 availability zones
        - it is a NoSql DB...a key value database
        - SCALES to massive workloads, and it is a serverless database
            (In essence, serverless databases offer a convenient and scalable way to manage your application's data
            without worrying about server infrastructure.)
        - in the hands on example you will see that you do not create a server/instance ...just a table ...
        - low latency retrieval

        - Dynamo DB Accelerator - aka DAX - is a fully managed in memory cache for DynamoDB... DAX offeres a 10x improvement
        when accessing data; difference between DAX and ElastiCache is that DAX is only for DynamoDB, while ElastiCache can
        be used for other DBs

    Redshift
        - based on PostgreSql, but it is not used for OLTP (online transaction processing)...this is what RDS is good for,
         but it is good for OLAP (online analytical and processing),...so good for using data warehousing and generating
         reports etc
        - data is loaded into it every hour, not every second
        - it has a feature called MPP (masively parallel query execution) which is used to perform the reporting computations
        very quickly

    Amazon EMR (elastic map reduce)
        - it is used to create Hadoop clusters (Big Data) to analyze and process large amounts of data
        - the clusters can be made of hundreds of EC2 instances
        - EMR takes care of provisioning and configuring all those EC2 instances to work together

    Amazon Athena
        - serverless query service to perform analytics against S3 objects
        - use standard SQL language to query the files

    Amazon QuickSight
        - serverless machine learning powered business intelligence service to create interactive dashboards
        - in order words, a tool for creating a dashboard over your data, that you can use to get insights into what is
        happening in your app
        - it is integrated with RDS, Aurora, Athena, Redshift, S3..

    Document DB
        - DocumentDB is the AWS implementation for MongoDB, just like Aurora is for the MySql/Postgres, which are relational
        DBs
        - so it is a NoSQL db
        - so it is compatible with MongoDB, which is used to store, query and index JSON data
        - similarly with Aurora, it is fully managed, highly available with replication over 3 availability zones

    Amazon Neptune
        - this is a graph DB

    Amazon QLDB
        - quantum ledger DB
        - a ledger is a book recording of financial transactions
        - fully managed, serverless, highly available, replication across 3 AZ
        - USED to review history of all the changes made to your application data over time
        - no entry can be removed or modified...data is cryptographically verifiable !!!!
        - although it sounds familiar to blockchain, this has a central authority component where data is stored ...so
        QLDB does not have descentralization

    Amazon Managed Blockchain
        - allows to build applications where multiple parties can execute transactions, without the need for a trusted,
        central authority...so it is descentralized
        - at the time of this course, this was compatible with the frameworks ethereum and hyperledger fabric

    DMS
        - database migration service
        - so this runs on a EC2 instance, and takes data from a source database and writes data to a target database
        - it supports homogeneous migrations, meaning from Oracle DB to Oracle DB
        - also supports heterogeneous migrations, for ex from MS Sql Server to Aurora

    AWS Glue
        - is a extract transform and load (ETL) service


==============================================================================================================
10 Other Compute Services_ ECS, Lambda, Batch, Lightsail

    ECS
        - Elastic Container Service
        - this is used to launch docker containers on AWS
        - you need to provision and maintain the infrastructure (the EC2 instances)

    Fargate
        - also used to launch docker containers on AWS
        - the difference from ECS is that with Fargate you do not need to provision the infrastructure...no EC2 instances to
        manage
        - AWS just runs the containers with the RAM and CPU that you need

    ECR
        - Elastic Container Registry
        - this is a private docker registry on AWS
        - this is where you need to store the AWS images in order to be able to run them on ECS or Fargate

    Serverless
        - means a new paradigm in which developers don't need to manage servers anymore...they just deploy the code
        - it was pioneered by AWS lambda, but now includes anything that is managed ...databases, messaging, storage..
        - it doesn't mean that there are no servers...it just means that developers don't need to manage / see the servers
        - examples : AWS S3, DynamoDB, Fargate...Lambda

    Lambda
        - so ...we talked about EC2...which is limited by RAM and CPU and runs continuously, even though we do not need
        it all the time
        - with Lambda, we just have virtual functions...that are limited by time...and they run on demand
        - scaling is automated !!!!
        - it is event-driven meaning that functions get called by AWS when needed.

    Amazon API Gateway
        - think of the example where you want to build a serverless API...a browser client makes REST calls...but these
        calls can't target Lambda directly...so they pass through the API Gateway, which in turn can call Lambda..which
        in turn can call Dynamo DB for example..
        - so API Gateway allows developers to easily create, publish, maintain, monitor and secure APIs

        Dan: see "10-1 API gateway usage.png"

    AWS Batch
        - a batch job is a job that has a start and end time
        - batch will dynamically launch EC2 instances or Spot instances
        - batch jobs run as Docker images

    Amazon Lightsail
        - it is a simpler alternative to using EC2, RDS, ELB, EBS, Route 53
        - great for people with little cloud experience...but it doesn't offer the full configurations available when you
        configure each of those services mentioned above for your app..


==============================================================================================================
11 Deployments & Managing Infrastructure at Scale

    Cloud Formation
        - is a declarative way (uses yaml or JSON format) of outlining your AWS infrastructure, for any resources
        - benefits of cloud formation:
            - infrastructure as code ...this means that you will not need to create resources manually from the WEB UI
            console; any modifications in the infrastructure can be reviewed through code review
            - costs : you get a resource identifier for each resource, so you can then easily track how much that resource
            costs you; also you can estimate the costs of your resources with CloudFormation template; also because Cloud
            Formation makes it easy to create AWS resources/services/instances, you can have costs saving...for example you can
            clean all the resources from AWS at 5pm, when developers leave work, and recreate them in morning at 8 AM
            automatically when the devs start working again
            - you don't need to reinvent the wheel...you can use existing Cloud Formation templates found online
            - you can generate diagrams of the resources used out of the template
        - in the web console there is an Application Composer, a web UI tool that one can use to create the diagram of
        the cloud, and generate the Cloud Formation configuration in either yaml or JSON

    Amazon Cloud Development Kit (CDK)
        - ALLOWS you to define the infrastructure using a programming language like Java
        - the code will eventually be translated into a Cloud Formation json/yaml file

    AWS Elastic Beanstalk
        - a developer centric view of deploying an application on AWS
        - THIS is a Platform as a Service (PaaS)
        - so you provide the jar/war , make some UI configs, and then the app is stated

    AWS Code deploy
        - a way to deploy code automatically
        - works with multiple EC2 instances, and with on premises servers (so AWS Code deploy is a hybrid service)

    AWS Code commit
        - is Amazons answer to GitHub ..
        - source control service that hosts git based repositories

    AWS Code build
        - builds code in cloud...compiles code, runs tests, creates packages
        - you only pay for build time...and it is fully managed, serverless

    AWS Code pipeline
        - orchestrate different steps needed to have code automatically pushed into production
        - code goes from Code Commit -> Code Build -> Code deploy -> Elastic Beanstalk

    AWS Code artifact
        - some sort of repository where artifacts can be stored (like Artifactory )

    AWS Code star
        - AWS CodeStar enables you to quickly develop, build, and deploy applications on AWS. AWS CodeStar provides
        a unified user interface, enabling you to easily manage your software development activities in one place.
        With AWS CodeStar, you can set up your entire continuous delivery toolchain in minutes, allowing you to start
        releasing code faster.

    AWS Cloud9
        - is a cloud IDE that you can use to edit run debug code in the cloud

    AWS systems manager (SSM)
        - get operational insights about your infrastructure
        - run commands across your fleet of servers
        - store parameter configuration with the SSM Parameter store
        - and many other managing functionalities


==============================================================================================================
12. Leveraging the AWS Global Infrastructure

    AWS Route 53
        - managed DNS ...a DNS is like a phone book, a collection of rules and records which help clients understand
        how to reach a server through URLs

            Dan: see "12-1 how a DNS works at a high level.png"

        - for exam you need to know the high level Routing policies:
            - simple routing policy: no healt checks ..browser calls Route 53 to get the IP...
            - weighted routing policy : Route 53 needs to select from several EC2 instances, and each of these has a different
                weight.. 70% 20% 10%..and this means that clients will be calling 70% of the time the first EC2 instance,
                20% the second one etc  (some kind of load balancing)
            - latency routing policy: if your app is distributed globally, and you have EC2 instances in California and
                Australia, and users all around the world, this policy will look at where the user is, and if he is close to
                California he will be redirected to those EC2s ...based on latency
            - failover routing policy: here Route 53 performs a health check on the EC2, which if it fails, it will redirect
                calls to another healthier EC2 instance

        - YOU HAVE the possibility to Register domains inside AWS Route 53
!!!!!   - 144 Route 53 Hands On.mp4
                Dan: very good tutorial of starting 2 EC2 instances in different regions, and registering them in Route 53
                    and by using a domain name, users get directed to the best EC2 instance
                    He used a vpn to simulate the fact that he is in another region of the world, so that the EC2 instance
                    closer to that region was serving requests.

    AWS Cloudfront
        - is a CDN
        - improves read performance as content is cached at edge
        - it offers DDOS protection , AWS Web App Firewall
        - it can cache from S3 buckets, Custom origin (HTTP) ..application load balancer, EC2 instance, or any http backend
        - great for static content that must be available everywhere

    AWS Global Accelerator
        - improves availability and performance by using the AWS global network
        - this works by having users connect to Edge locations, and then redirected to the resource through the AWS network
        - difference between this and CLoudfront is that CloudFront provides caching, while the Global Accelerator just
        passes the information through the AWS network for faster response times

    AWS Wavelength
        - bring AWS services to the edge of 5g networks..in order to provide low latency through the use of 5G networks

==============================================================================================================
13 Cloud Integrations

    Amazon SQS - Simple queue Service
        - Dan see "13-1 Simple Queue Service.png"
        - fully managed (so it is serverless), used to decouple applications
        - scales from 1 message per second to 10000 messaages per second
        - default retention period : 4 days ...maximum retention period is 14 days
        - no limit how many messages can be in the queue

    Amazon SNS - Simple notification Service
        - for when you want to send a message to multiple reciever apps
        Dan see "13-2 Simple notification service.png"
        - each topic can have 12 million subscriptions (meaning apps that process notifications..like
        AWS lambdas, Email sending apps, http and https endpoints etc)

    Amazon Kinesis
        - real time big data streaming
        - it is a managed service, used to collect, process and analyze real time streaming data at any
        scale

    Amazon MQ
        - SQS and SNS are "cloud native" services, and they are using propietary protocols from AWS
        - SO if you are migrating a solution to the cloud, instead of re-engineering/adapting the app to
         the SQS or SNS you can use Amazon MQ
        - this is a managed Apache ActiveMQ
        - amazon MQ DOES not scale like SQS or SNS...you need to have a dedicated machine in AWS


==============================================================================================================
14 Cloud Monitoring

    CloudWatch
        - provides metrics for every AWS service
        - metrics have timestamps
        - important metrics:
            - EC2 instances : CPU utilisation, Status check, Network
            - EBS volumes : disk Read/Write
            - S3 bucket : bucket size in bytes, number of objects stored,
            - billing : at the time of the course, this metric was only available in a US zone

        - cloudWatch alarms are used to trigger notification for any metric...So when a metric goes
        above a value, an alarm action can be triggered...for example:
            - increase or decrease the number of EC2 instances
            - stop, terminate, reboot EC2 instance
            - SNS notification..meaning sending a notification in a SNS topic

        - cloudwatch logs can collect log from:
            - AWS Lambda
            - Elastic Beanstalk
            - ECS (elastic container service)
            - cloudwatch log agents: when you install on EC2 machines or on premise servers
            - route 53 - logging DNS queries

        - by default, no logs from EC2 instance will go to CloudWatch...you need to run a CloudWatch
        agent on EC2 instance to push the log files that you want

        - cloudwatch events
            - event pattern : event rules to react to a service doing something...for example a IAM root
            user sign in could trigger an email notification
            - so these events can trigger lambda functions or SQS/SNS messages..

        - Amazon EventBridge
            - is the next evolution of CloudWatch events
            - default event bus, generated by AWS services
            - partner event bus -> receive events from SaaS service or applications (DataDog, Zendesk)
            - custom event bus -> for your own applications

    AWS Cloud trail
        - provides governance, compliance and audit for your AWS account
        - enabled by default
        - get a history of events / API calls made with your AWS account by :
            - console
            - SDK
            - CLI
        - cloud trail logs can be put in S3 or CloudWatch logs
        - events are  stored for 90 days ...if you want to store them for longer periods of time, you need
        to log them into S3 and use Athena to query them

    AWS X-ray
        - problem: debugging one monolith app is easy...however debugging distributed services is hard..
        and this is where X-ray comes in
        - it provides visual analysis of your application...
        - it is useful for :
            - troubleshooting performance (bottlenecks)
            - understand dependencies in a microservice architecture
            - pinpoint service issues
            - are we meeting Service level agreement (uptime) ?

    Amazon CodeGuru
        - automated code reviews powered by machine learning (static code analysis)
        - also provides application performance recommendations
        - supports java and python
        - integrates with github, bitbucket, AWS code commit
        - it also has a profiler that can be used to debug performance issues

    AWS Personal health dashboard
        - provides alerts and remediation guidance when AWS is experiencing events that may impact you



==============================================================================================================
15 VPC & Networking

    VPC Virtual Private Cloud
        - this is something that you should know in depth for the AWS Certified solutions architect associate
        - private network for you as a developer to deploy your resources in (specific to a region..so if you have
        multiple regions, you need multiple VPCs)

    Subnet
        - allow you to partition your network inside your VPC (availability zone resource)
        - a PUBLIC subnet is a subnet that is accessible from the internet. Here one would place a load
        balancer
        - a PRIVATE subnet is a subnet that is not accessible from the internet... here one would place
        the databases for example, because the DB does not need direct access to internet, as data goes
        through an EC2 first for example

    Route tables
        - to define access to the internet and between subnets, we use Route Tables

    CIDR range
        - range of IP addresses allowed in your VPC

        Dan: see "15-1 VPC diagram example.png"

    Internet Gateway and NAT gateway
        - internet gateway help our VPC instances to connect to the internet
        - set up per VPC level
        - public subnets have a route to the internet gateway
        - NAT gateways (AWS managed) and NAT instances (self managed) allow your instances in your
        Private Subnets to access the internet while remaining private...this is useful for example for
        updating the software in those private subnets

        - a route is created from the private subnet to the NAT gateway (which is located in the public
        subnet), and from the NAT gateway to the Internet gateway...and this will allow the private subnets
        to have internet connectivity

        Dan: see "15-2 Internet and NAT gateways.png" for example

    Network ACL (access control lists) & Security Groups
        Network ACL
            - is a firewall which controls traffic to and from the subnet
            - so this is set up at subnet level
            - can have allow and deny rules...the rules include only IP addresses

        Security Groups
            - firewall that controlls traffic to and from a ENI (elastic network interface) or an EC2 instance
            - so this is set up at EC2/ENI level
            - can only have allow rules
            - the rules include either IP addresses and other security groups

        Dan: see "15-3 network ACL and Security Groups.png"

    VPC flow logs
        - capture information about IP traffic going into your interfaces
        - you can get :
            - VPC flow log
            - subnet flow log
            - Elastic network interface flow log
        - these help in monitoring and troubleshooting connectivity issues like
            - subnet to internet
            - subnets to subnets
            - internet to subnets
        - these logs can go to S3 or CloudWatch logs

    VPC endpoints
        - allow you to connect to AWS services using a private network instead of the public www network..
        this gives you higher security and lower latency to access AWS services


==============================================================================================================
16 Security & Compliance

    AWS Shared Responsibility Model
        - AWS Responsibility = security of the cloud
            - ...meaning protecting the infrastructure (hardware software facilities network) that run the AWS
            Services...also managed services like S3, DynamoDB
        - Customer Responsibility = security in the cloud
            - for an EC2 instance, customer is responsible for management of the guest OS (including security
            patches and updates), firewall and network configuration, IAM
            - enrypting application data also falls here

        - lets take the example of RDS
            - AWS responsibility
                - managed underlying EC2, disable ssh
                - automated DB patching
                - automated OS patching
                - audit of the underlying instance and disk
            - Developer / Customer responsibility
                - check the ports / IPs / security group inbound rules in DB security group
                - encryption of data
                - creating a DB with or without public access

        - this shared responsibility topic has 2 3 questions in the exam

    DDOS attack
        - distributed denial of service

        - AWS Shield standard : protection against DDOS attacks for your website and apps for all customers at no
            additional cost..this is activated for every customer
        - AWS Shield Advanced : 24/7 premium DDOS protection...it  costs about 3000$ per month per organization..
            this also provides protection against higher consumption costs caused by DDoS
        - AWS WAF (web app firewall) ...filter specific requests based on rules
            - you can define WEB ACL (access control lists) ....the rules can include HTTP headers, IP addresses,
            HTTP body...geo location rules, to block access from some countries... also rate-based rules, that
            can be defined like for example a user should not be able to make more than 5 requests per second, to
            protect against DDoS
        - CloudFront and Route53 also help by providing availability by using the global edge network

    Encryption with KMS and Cloud HSM
        - data at rest
            - is data stored or archived on a device
            - on a hard disk, on a RDS instance, S3 glacier deep archive
        - data in transit
            - transfer from on premise to AWS, EC2 to DynamoDB
            - data transfered on the network
        - we want to encrypt both states to protect it...and for encryption we use encryption keys

        - Amazon KMS (key management service)
            - AWS will manage the encryption keys for us
            - encryption opt in :
                - EBS volumes : encrypt volumes
                - S3 buckets : server side encryption of objects
                - RDS db : encryption of data
                - EFS drives : encryption of data
            - encryption automatically enabled in :
                - S3 glacier
                - cloudtrail logs
                - storage gateway

        - Cloud HSM (hardware security module)
            - this means that aws provides dedicated encryption hardware...and you the customer/developer manages the
            the encryption keys entirely
            - HSM device is tamper resistent

    AWS Certificate Manager (ACM)
        - lets you provision manage and deploy SSL/TLS certificates
        - used to provide in flight encryption for websites (HTTPS)
        - SUPPORTS both private and public TLS certificates
        - it is free of charge for public TLS certificates...and you also get automatic certificate renewal
            Dan: see "16-1  Amazon Certificate manager.png"

    AWS Secrets manager
        - used for storing secrets...also has a capability to force the rotation of secrets every X days
        - secrets are encrypted with KMS
        - this is a paid service
        - what can a secret be ? credentials for RDS, Document DB, API keys,

    AWS GuardDuty
        - intelligent threat discovery to protect AWS account
        - uses ML + anomaly detection + 3rd party data

    AWS Inspector
        - performs automatic security assessment of EC2 instances and containers


==============================================================================================================
17. Machine Learning

    Amazon Rekognition
        - find objects people text scenes in images and videos using ML
        - facial analysis and facial search to do user verification, people counting

    Amazon transcribe
        - convert speech to text

    Amazon polly
        - convert text to speech

    Amazon translate
        - language translation

    Amazon Lex
        - same technology that powers Alexa

    Amazon Connect
        - recieve calls, create contact flows, cloud based virtual contact center
        - can integrate with other CRMs or AWS

        Dan see "17-1 amazon lex + connect + lamba example.png"

    Amazon Comprehend
        - fully managed and serverless
        - uses machine learning to find insights and relationships in text
        - use case example: you get email from customers concerning feedback... and you want to make an analysis
        as to how pozitive or negative the sentiment is

    Amazon Forecast
        - fully managed service using ML to deliver highly accurate forecasts
        - example: predict the future sales of a raincoat..

    Amazon Personalize
        - fully managed ML service, to build apps with real time personalized recommendations
        - example: a user bought some gardening tools...provide recommendations on products that he can also buy
        - same technology used by amazon.com


==============================================================================================================
18 Account Management, Billing & Support

    AWS Organizations
        - allows the management of multiple AWS accounts
        - billing is consolidated across all accounts ...only the master account pays

        - organizational units (OU) enable you to group several accounts together and administer them as
        a single unit instead of one at a time

        - SCP (service control policies) enable central administration over the permissions available withing
        the accounts in your organization

    AWS Control tower
        - easy way to set up and govern a secure and compliant multi account AWS environment based on best
        practices

    AWS Pricing models
        1. pay as you go ...pay for what you use remain agile
        2. save when you reserve ...manage budgets predictably, comply with long term requirements, make EC2 reservations
        3. pay less by using more ..volume based discounts
        4. pay less as AWS grows...because of economies of scale ...they are famous for passing price cuts to customers

        Dan: this video contains a lot of information on pricing for various AWS services...

    AWS Savings plan
        - Savings Plans are a flexible pricing model that offer low prices on AWS usage, in exchange for a
        commitment to a consistent amount of usage (measured in $/hour) for a 1- or 3-year term

    AWS Compute optimizer
        - allows you to reduce costs and prove performance by recommanding optimal AWS resources for your workloads

    AWS Pricing calculator
!!!!! - estimates how much you will have to pay
        https://calculator.aws/#/estimate

    Trusted advisor
        - nice tool that looks over the resources that you are using, and provides feedback for costs, security,
        performance, fault tolerance, service limits

    AWS Support plans
        - based on what support plan you pay for, you have better support from amazon ...like help from their support
        team.
        - there are several levels, the more expensive the faster/better the support


==============================================================================================================
19 Advanced Identity

    AWS STS
        - security token service
        - enables you to create temporary limited priviledges credentials to access AWS resources
        - you can configure the expiration period

!!!!AWS Cognito
        - provides identity for your Web and Mobile application users
        - Amazon Cognito provides authentication, authorization, and user management for your web and mobile apps.
        - It’s a user directory, an authentication server, and an authorization service for OAuth 2.0 access
        tokens and AWS credentials. With Amazon Cognito, you can authenticate and authorize users from the
        built-in user directory, from your enterprise directory, and from consumer identity providers like
        Google and Facebook.

    AWS SSO
        - single sign on
        - one login for multiple AWS accounts and applications


==============================================================================================================
20 Other services

    - contains services that are not groupable in the other chapters..

    Amazon Workspace
        - managed desktop as a service (DaaS) solution to provision Windows or Linux desktops

    Amazon AppStream 2.0
        - desktop application streaming service
        - the application is delivered in your web browser...so you can use Eclipse in your browser etc

    Amazon Sumerian
        - can be used to create and run virtual reality , augmented reality, and 3D apps

    Amazon Elastic Transcoder
        - used to transform media files stored in S3 into media formats required by various playback devices (
        prones, tablets tvs etc)

    AWS Device farm
        - fully managed service that tests your web and mobile apps against desktop browsers, real mobile devices
        and tables
        - you have the ability to configure device settings, like GPS, WIFI, bluetooth etc
        - the output is generated reports, logs, screenshots etc

    AWS backup
        - create backups automatically for various services, like EC2, RDS, Aurora and stores them in S3

    AWS Fault injection simulator (FIS)
        -based on chaos engineering, this will stress an application by creating disruptive events and observing
        how the system responds
        - helps with uncovering hidden bugs, performance bottlenecks


==============================================================================================================
21 AWS Architecting & Ecosystem

    Well architected framework - general guiding principles
        - stop guessing your capacity needs
        - test system as production scale
        - automate (ex by using infrastructure as code) to make architectural experimentation easier

        - think in services not in servers...don't just use EC2s..used managed services like databases,
        serverless

    1st pillar_ Operational Excellence
        - infrastructure as code -> AWS CloudFormation
        - automate the creation of annotated documentation after every build
        - make small frequent reversible changes...so that in case of failure you can quickly reverse it

    2nd pillar_ Security
        -

    3rd pillar_ Reliability

    4th pillar_ Performance efficiency

    5th pillar_ Cost optimization

    6th pillar_ Sustainability

    AWS Well-Architected Tool
        The AWS Well-Architected Tool helps you review your workloads against current AWS best practices and
        provides guidance on how to improve your cloud architectures. This tool is based on the AWS
        Well-Architected Framework.

==============================================================================================================
22 Preparing for the Exam + Practice Exam - AWS Certified Cloud Practitioner




==============================================================================================================



TODO Whenever you run into a problem with the course, maybe you can try and look over the videos of this other course:
    https://www.youtube.com/watch?v=bO25vbkoJlA&list=PL7iMyoQPMtAN4xl6oWzafqJebfay7K8KP

TODO AWS Certified Cloud Practitioner Certification Course (CLF-C02) - Pass the Exam!
    https://www.youtube.com/watch?v=NhDYbskXRgc&pp=ygUNYXdzIGxpZ2h0c2FpbA%3D%3D

TODO  Playlist about various AWS services
    https://www.youtube.com/watch?v=W6jQmVi31Xk&list=PLwyXYwu8kL0wg9R_VMeXy0JiK5_c70IrV

!!!  Dan: very good explanation of network settings needed in AWS. This fixed my issues with connecting to the EC2 inbound
        and outboud
            see "AWS VPC Subnet InternetGateway RouteTable.png"
    AWS how to setup VPC, Public, Private Subnet, NAT, Internet Gateway, Route Table?
        https://www.youtube.com/watch?v=43tIX7901Gs

    AWS ALB (Application Load Balancer) - Step By Step Tutorial (Part -9)               !!!! very good stuff
        https://www.youtube.com/watch?v=cuJTmBvFCS0

https://stackoverflow.com/questions/10253484/cant-access-site-on-ec2-instance-via-public-ip









































